
*4ì›” 4ì£¼ì°¨*

```Data engineering/ ml```
> `MLlib.md`, `recommendation.md`, `kafka.md`, `airflow.md`, `2ì°¨ í‰ê°€ ì¤€ë¹„ (notionì— ì •ë¦¬ì¤‘)

_#ë‚´ë§˜ëŒ€ë¡œTILì±Œë¦°ì§€ #ë™ì•„ì¼ë³´ #ë¯¸ë””ì–´í”„ë¡ í‹°ì–´ #ê¸€ë¡œë²Œì†Œí”„íŠ¸ì›¨ì–´ìº í¼ìŠ¤ #GSCì‹ ì´Œ_

_ê¸€ë¡œë²Œì†Œí”„íŠ¸ì›¨ì–´ìº í¼ìŠ¤ì™€ ë™ì•„ì¼ë³´ê°€ í•¨ê»˜ ì§„í–‰í•˜ëŠ” ì±Œë¦°ì§€ì…ë‹ˆë‹¤._


---


# Regression
> zeppelinì—ì„œ ml ëª¨ë“ˆì„ ì‚¬ìš©í•˜ì—¬ regressionì„ ìˆ˜í–‰í•  ìˆ˜ ìˆë‹¤.

- `fish.csv` íŒŒì¼ì„ ì´ìš©í•´ì„œ ì„ í˜• íšŒê·€ (regression) ëª¨ë¸ì„ ìƒì„±í•˜ê³  ì˜ˆì¸¡í•œë‹¤.

```spark-shell
file_path = 'hdfs://localhost:9000/input/fish.csv'
# file_path = 'file:///home/ubuntu/damf2/data/fish.csv'
```
> csv íŒŒì¼ ìœ„ì¹˜ ì•Œë ¤ì£¼ëŠ” ì½”ë“œëŠ” ìœ„ì™€ ê°™ì´ `file_path`ë¥¼ ì§€ì •í•´ì„œ ì•Œë ¤ì¤Œ. 

```spark-shell
%pyspark
from pyspark.ml.feature import StringIndexer
indexer = StringIndexer(inputCols=['Species'], outputCols=['species_idx'])
df = indexer.fit(df).transform(df)
```
![fish_regression](/assets/fish_regression.png)

---
## í˜‘ì—… í•„í„°ë§ (collaborative filtering)

- ì¶”ì²œ
- zeppelin `5.recommendation.md`
#### pyspark ë‚´ë¶€ì˜ `ALS`ë¥¼ ì´ìš©í•´ì„œ


![alt](https://miro.medium.com/v2/resize:fit:1400/1*mGkhWAAHcuDgl4XRvyFX9w.png)

--- 
## Classification
```python
file_path = 'hdfs://localhost:9000/input/fish.csv'
df = spark.read.csv(file_path, header=True, inferSchema=True)

# ============

from pyspark.sql.functions import col
df = df.filter(col('Species').isin('Bream', 'Smelt'))

# ============

from pyspark.sql.functions import when
from pyspark.sql.functions import col
df = df.withColumn(
    'species_idx',
    when(col('Species') == 'Bream', 1)
    .otherwise(0)
)

# ============

from pyspark.ml.feature import VectorAssembler

assembler = VectorAssembler(
    inputCols=[
        'Weight',
        'Length1',
        'Length2',
        'Length3',
        'Height',
        'Width'
    ],
    outputCol='features'
)
df = assembler.transform(df)

# ============

train_data, test_data = df.randomSplit([0.8, 0.2])

# ============

from pyspark.ml.classification import LogisticRegression

lr = LogisticRegression(featuresCol='features', labelCol='species_idx')
lr_model = lr.fit(train_data)

# ============

prediction = lr_model.transform(test_data)

# ============

from pyspark.ml.evaluation import BinaryClassificationEvaluator

evaluator = BinaryClassificationEvaluator(labelCol='species_idx', rawPredictionCol='rawPrediction', metricName='areaUnderROC')
result = evaluator.evaluate(prediction)
print(result)

# ============

from pyspark.ml.classification import RandomForestClassifier

rf = RandomForestClassifier(featuresCol='features', labelCol='species_idx', maxBins=500)
rf_model = rf.fit(train_data)

# ============

prediction = rf_model.transform(test_data)
prediction.show()

```

---
## Streaming
-zeppelin `6.streaming`

![spark_streaming](/assets/spark_streaming.png)

---

## Kafka
- zeppelin `7.kafka`

- kafka ì„¤ì¹˜
- kafka ì‹¤í–‰
- kafka í…ŒìŠ¤íŠ¸

> kafkaëŠ” ë©”ì‹œì§€ íë¼ëŠ” ê°œë…ìœ¼ë¡œ, kafkaëŠ” ë©”ì‹œì§€ë¥¼ ì €ì¥í•˜ëŠ” íì´ë‹¤.
![kafka_pub_sub_ë©”ì‹œì§€í](/assets/kafka_pub_sub.webp)

> ë¬´ì¸íƒë°°í•¨ê³¼ ë¹„ìŠ·í•œ ê°œë…
>
> ëˆ„ê°€ ë°›ëŠ”ì§€ / ìˆ˜ì‹ ìëŠ” ê´€ì‹¬ ì—†ìŒ - ë³´ë‚´ëŠ” ì…ì¥ (publisher) ì˜ ì—­í• ë§Œ - ë³´ë‚´ê¸°ë§Œ / kafkaê°€ ì €ì¥ => subscriber ì…ì¥ì—ì„œëŠ” ë³´ë‚´ì˜¨ ë°ì´í„°ê°€ ìˆë‹¤ë©´ ì½ì„ë¿
>
>
> 'topic': kafkaê°€ ë“¤ì–´ì˜¤ëŠ” ë°ì´í„°ë¥¼ ê³„ì† ìŒ“ëŠ” ì¤‘ê°„ë‹¤ë¦¬ì˜ ì—­í• 
>

## kafka ë‹¤ìš´ë¡œë“œ 
~ìœ„ì¹˜ì—ì„œ 
```shell
wget https://dlcdn.apache.org/kafka/3.9.0/kafka_2.13-3.9.0.tgz
```

- unzip
```shell
tar -zxvf kafka_2.13-3.9.0.tgz
```
- zookeeper ì‹¤í–‰
```shell
bin/zookeeper-server-start.sh -daemon config/zookeeper.properties
```
- kafka ì‹¤í–‰
```shell
bin/kafka-server-start.sh -daemon config/server.properties
```


![alt text](image.png)
> interpreter (zeppelin ì„¤ì •ì„ ë°”ê¿ˆ) => kafkaì™€ sparkë¥¼ ì—°ê²°í•˜ê¸° ìœ„í•´ì„œ

---
# Airflow
## Airflow

> ìë™í™”ëœ ì‘ì—…ì„ ìœ„í•œ ì˜¤í”ˆì†ŒìŠ¤ ê´€ë¦¬ì í”„ë¡œê·¸ë¨

- AirflowëŠ” DAG(Directed Acyclic Graph)ì„ ì´ìš©í•´ ì‘ì—…ì„ ê´€ë¦¬í•œë‹¤.
- DAGëŠ” ì‘ì—…ì˜ ìˆœì„œë¥¼ ì •ì˜

---
### Airflowì˜ êµ¬ì„±ìš”ì†Œ

- `DAG` : ì‘ì—…ì˜ ìˆœì„œë¥¼ ì •ì˜
- `Task` : ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” ë‹¨ìœ„
- `Operator` : ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” í´ë˜ìŠ¤
- `Sensors` : ì‘ì—…ì´ ëë‚˜ëŠ” ê²ƒì„ ê°ì§€í•˜ëŠ” í´ë˜ìŠ¤
- `Trigger` : DAGë¥¼ ì‹œì‘í•˜ëŠ” í´ë˜ìŠ¤
- `Task Instance` : DAGì—ì„œ ìˆ˜í–‰ë˜ëŠ” ì‘ì—…
- `Log` : ì‘ì—…ì˜ ì‹¤í–‰ ê²°ê³¼ë¥¼ ë¡œê·¸ë¡œ ë‚¨ê¹€
- `Sla` : ì‘ì—…ì´ ëë‚˜ëŠ” ì‹œê°„ì„ ì œí•œí•˜ëŠ” í´ë˜ìŠ¤

---
### DAG

: ì‘ì—…ì˜ ìˆœì„œë¥¼ ì •ì˜

: ì‹œê°ì ìœ¼ë¡œ ë³´ê¸° ì¢‹ê²Œ ë§Œë“¤ì–´ì£¼ê³ 

: ê°ê°ì˜ íë¦„ì„ ë³´ê¸° ì¢‹ê²Œ 
- íŠ¹ì • ì‹œê°„ë§ˆë‹¤ workflowë¥¼ ê´€ë¦¬í•˜ëŠ” process

`DAG` : ìœ í–¥ `ë¹„ìˆœí™˜` ê·¸ë˜í”„ -> ë°©í–¥ì„±ì€ ìˆì§€ë§Œ, ìˆœí™˜ì€ ë˜ì§€ ì•ŠëŠ” ì‘ì—…ë“¤
=> ì‹œì‘ì´ ìˆë‹¤ë©´ ëì´ ìˆëŠ” ì‘ì—…

---
- task
- graph


---
# 2ì°¨ í‰ê°€ ì¤€ë¹„

ë¬¼ë¡ ì…ë‹ˆë‹¤! ğŸš€

ã…¡ã…¡

## ORM vs SQL

| ê¸°ëŠ¥ | ORM (Django ORM) | SQL |
| --- | --- | --- |
| ì „ì²´ ì¡°íšŒ (SELECT) | `Model.objects.all()` | `SELECT * FROM í…Œì´ë¸”ëª…;` |
| í‹€ì • ì¡°ê±´ ì¡°íšŒ (WHERE) | `Model.objects.filter(ì»¬ëŸ¼='ê°’')` | `SELECT * FROM í…Œì´ë¸”ëª… WHERE ì»¬ëŸ¼='ê°’';` |
| ì •ë ¬ (ORDER BY) | `Model.objects.all().order_by('ì»¬ëŸ¼')` | `SELECT * FROM í…Œì´ë¸”ëª… ORDER BY ì»¬ëŸ¼ ASC;` |
| ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬ (ORDER BY DESC) | `Model.objects.all().order_by('-ì»¬ëŸ¼')` | `SELECT * FROM í…Œì´ë¸”ëª… ORDER BY ì»¬ëŸ¼ DESC;` |
| í‹€ì • ì»¬ëŸ¼ë§Œ ì¡°íšŒ (SELECT í‹€ì • ì»¬ëŸ¼) | `Model.objects.values('ì»¬ëŸ¼1', 'ì»¬ëŸ¼2')` | `SELECT ì»¬ëŸ¼1, ì»¬ëŸ¼2 FROM í…Œì´ë¸”ëª…;` |
| ì¤‘ë³µ ì œê±° (DISTINCT) | `Model.objects.values('ì»¬ëŸ¼').distinct()` | `SELECT DISTINCT ì»¬ëŸ¼ FROM í…Œì´ë¸”ëª…;` |
| ë°ì´í„° ì‚½ì… (INSERT) | `Model.objects.create(ì»¬ëŸ¼='ê°’', ì»¬ëŸ¼2='ê°’2')` | `INSERT INTO í…Œì´ë¸”ëª… (ì»¬ëŸ¼, ì»¬ëŸ¼2) VALUES ('ê°’', 'ê°’2');` |
| ë°ì´í„° ìˆ˜ì • (UPDATE) | `Model.objects.filter(ì¡°ê±´).update(ì»¬ëŸ¼='ìƒˆê°’')` | `UPDATE í…Œì´ë¸”ëª… SET ì»¬ëŸ¼='ìƒˆê°’' WHERE ì¡°ê±´;` |
| ë°ì´í„° ì‚­ì œ (DELETE) | `Model.objects.filter(ì¡°ê±´).delete()` | `DELETE FROM í…Œì´ë¸”ëª… WHERE ì¡°ê±´;` |
| AND ì¡°ê±´ ì¡°íšŒ | `Model.objects.filter(ì»¬ëŸ¼1='ê°’1', ì»¬ëŸ¼2='ê°’2')` | `SELECT * FROM í…Œì´ë¸”ëª… WHERE ì»¬ëŸ¼1='ê°’1' AND ì»¬ëŸ¼2='ê°’2';` |
| OR ì¡°ê±´ ì¡°íšŒ | `Model.objects.filter(Q(ì»¬ëŸ¼1='ê°’1') | Q(ì»¬ëŸ¼2='ê°’2'))` | `SELECT * FROM í…Œì´ë¸”ëª… WHERE ì»¬ëŸ¼1='ê°’1' OR ì»¬ëŸ¼2='ê°’2';` |
| JOIN (ë‚´ë¶€ ì¡°ì¸) | `ModelA.objects.select_related('ModelB')` | `SELECT * FROM A JOIN B ON A.í‚¤ = B.í‚¤;` |
| JOIN (ë‹¤ëŒ€ëŒ€ ì¡°ì¸) | `ModelA.objects.prefetch_related('ModelB')` | `SELECT * FROM A JOIN B ON A.id = B.a_id;` |
| ë¶€ëª¨ ê²€ìƒ‰ (LIKE) | `Model.objects.filter(ì»¬ëŸ¼__icontains='ê°’')` | `SELECT * FROM í…Œì´ë¸”ëª… WHERE ì»¬ëŸ¼ LIKE '%ê°’%';` |
| ë²”ìœ„ ê²€ìƒ‰ (BETWEEN) | `Model.objects.filter(ì»¬ëŸ¼__range=(ê°’1,ê°’2))` | `SELECT * FROM í…Œì´ë¸”ëª… WHERE ì»¬ëŸ¼ BETWEEN ê°’1 AND ê°’2;` |
| NULL ê°’ ì¡°íšŒ | `Model.objects.filter(ì»¬ëŸ¼__isnull=True)` | `SELECT * FROM í…Œì´ë¸”ëª… WHERE ì»¬ëŸ¼ IS NULL;` |
| IN ì¡°íšŒ | `Model.objects.filter(ì»¬ëŸ¼__in=[ê°’1, ê°’2, ê°’3])` | `SELECT * FROM í…Œì´ë¸”ëª… WHERE ì»¬ëŸ¼ IN (ê°’1, ê°’2, ê°’3);` |
| GROUP BY ì§€ê¸ˆ | `Model.objects.values('ì»¬ëŸ¼').annotate(Count('id'))` | `SELECT ì»¬ëŸ¼, COUNT(id) FROM í…Œì´ë¸”ëª… GROUP BY ì»¬ëŸ¼;` |
| GROUP BY + HAVING | `Model.objects.values('ì»¬ëŸ¼').annotate(Count('id')).filter(Count('id')__gte=10)` | `SELECT ì»¬ëŸ¼, COUNT(id) FROM í…Œì´ë¸”ëª… GROUP BY ì»¬ëŸ¼ HAVING COUNT(id) >= 10;` |


ã…¡ã…¡

**[1] ORM vs SQL ê¸°ë³¸ ë¬¸ë²• ë¹„êµí‘œ**

(í‘œ ë‚´ìš©ì€ ì´ì „ ì‘ì„±ê³¼ ë™ì¼)

---

**[2] ì£¼ìš” ì‹œë‚˜ë¦¬ì˜¤ë³„ ORM vs SQL ì½”ë“œ ë¹„êµ**

(í‘œ ë‚´ìš©ì€ ì´ì „ ì‘ì„±ê³¼ ë™ì¼)

---

# Insert - add new columns & values

### ORM
```python
Movie.objects.create(ì»¬ëŸ¼1='value1', ì»¬ëŸ¼2='value2')
```

### SQL
```sql
INSERT INTO Movie(ì»¬ëŸ¼1, ì»¬ëŸ¼2)
VALUES (value1, value2);
```

---

# SELECT : filtering, ê³¨ë¼ë‚´ê¸°

## ì „ì²´ ì¶œë ¥

### ORM
```python
Movie.objects.all()
```

### SQL
```sql
SELECT * FROM Movie;
```

## year ìˆœ ì •ë ¬

### ORM
```python
Movie.objects.all().order_by('year')
```

## year ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
```python
Movie.objects.all().order_by('-year')
```

### SQL
```sql
SELECT * FROM movies_movie
ORDER BY year DESC;
```

## ë‚˜ì´ê°€ 30ì‚´ì¸ ì‚¬ëŒ

### ORM
```python
User.objects.filter(age=30)
```

### SQL
```sql
SELECT * FROM movies_user
WHERE age=30;
```

## 20ëŒ€ë§Œ ì¡°íšŒ

### ORM
```python
User.objects.filter(age__gte=20, age__lt=30)
User.objects.filter(age__range=[20,29])
```

### SQL
```sql
SELECT * FROM movies_user
WHERE age >= 20 AND age < 30;

SELECT * FROM movies_user
WHERE age BETWEEN 20 AND 29;
```

## ê°œë´‰ë…„ë„ê°€ 2010ë…„ ì´í›„ ë˜ëŠ” 2000ë…„ ì´ì „

### ORM
```python
Movies.objects.filter(Q(year__lt=2000) | Q(year__gt=2010))
```

### SQL
```sql
SELECT * FROM movies_movie
WHERE year < 2000 OR year > 2010;
```

## ê°€ì¥ ìµœê·¼ì‘ ê³¨ë¼ë‚´ê¸°

### ORM
```python
Movie.objects.aggregate(Max('year'))
```

### SQL
```sql
SELECT MAX(year) FROM movies_movie;
```

## Userì˜ ë‚˜ì´ í‰ê· 

### ORM
```python
User.objects.aggregate(Avg('age'))
```

### SQL
```sql
SELECT AVG(age) FROM movies_user;
```

## 1ë²ˆ ì˜í™”ì˜ ìµœê³  í‰ì , í‰ê·  í‰ì 

### ORM
```python
Score.objects.filter(movie_id=1).aggregate(Max('value'), Avg('value'))
```

### SQL
```sql
SELECT MAX(value), AVG(value) FROM movies_score WHERE movie_id=1;
```

## 1ë²ˆ ìœ ì €ê°€ ë‚¨ê¸´ ëŒ“ê¸€ ê°œìˆ˜

### ORM
```python
Score.objects.filter(user_id=1).count()
```

### SQL
```sql
SELECT COUNT(value) FROM movies_score WHERE user_id=1;
```

## Theë¡œ ì‹œì‘í•˜ëŠ” ì˜í™”, í¬í•¨ëœ ì˜í™”

### ORM
```python
Movie.objects.filter(title__startswith='The')
Movie.objects.filter(title__icontains='The')
```

### SQL
```sql
SELECT * FROM movies_movie WHERE title LIKE 'The%';
SELECT * FROM movies_movie WHERE title LIKE '%The%';
```

## "on."ìœ¼ë¡œ ëë‚˜ëŠ” ì˜í™”

### ORM
```python
Movie.objects.filter(title__endswith='on.')
```

### SQL
```sql
SELECT * FROM movies_movie WHERE title LIKE '%on.';
```

## "g__d" íŒ¨í„´ ë§¤ì¹­

### SQL
```sql
SELECT * FROM movies_movie WHERE title LIKE '%g__d%';
```

---

# UPDATE

## ORM
```python
movie = Movie.objects.get(id=1)
movie.title = 'ìƒˆë¡œìš´ ì œëª©'
movie.save()
```

## SQL
```sql
SELECT * FROM movies_movie WHERE id=1;
UPDATE movies_movie SET title='Iron Man' WHERE id=1;
```

---

# DELETE

## ORM
```python
movie = Movie.objects.get(id=2)
movie.delete()
```

## SQL
```sql
DELETE FROM movies_movie WHERE id=2;
```

---

# JOIN

| ì‹œë‚˜ë¦¬ì˜¤ | ORM | SQL |
|:---|:---|:---|
| 1ë²ˆ ìœ ì €ê°€ ì‘ì„±í•œ ì ìˆ˜ | `User.objects.get(id=1).score_set.all()` ë˜ëŠ” `Score.objects.filter(user_id=1)` | `SELECT * FROM movies_user JOIN movies_score ON movies_user.id = movies_score.user_id WHERE movies_user.id = 1;` |
| 1ë²ˆ ìœ ì € ì´ë¦„ê³¼ ì ìˆ˜ ID | `Score.objects.filter(user_id=1).values('user__name', 'id')` | `SELECT name, movies_score.id FROM movies_user JOIN movies_score ON movies_user.id = movies_score.user_id WHERE movies_user.id = 1;` |
| 100ë²ˆ ì˜í™”ê°€ ì†í•œ ì¹´í…Œê³ ë¦¬ | `Movie.objects.get(id=100).categories.all()` | `SELECT * FROM movies_movie JOIN movies_category_movies ON movies_movie.id = movies_category_movies.movie_id JOIN movies_category ON movies_category_movies.category_id = movies_category.id WHERE movies_movie.id = 100;` |
| drama ì¹´í…Œê³ ë¦¬ì— ì†í•œ ì˜í™” | `Category.objects.get(name='drama').movies.all()` | `SELECT * FROM movies_movie JOIN movies_category_movies ON movies_movie.id = movies_category_movies.movie_id JOIN movies_category ON movies_category_movies.category_id = movies_category.id WHERE movies_category.name = 'drama';` |

---

# Book Data

 ë°ì´í„° ì •ì œ (books_view, ratings_view, users_view í…Œì´ë¸”ì„ ë³´ê¸° í†µê¸° data_type ë“±ì„ ì •ë ¬)

```sql
CREATE VIEW books_view AS
SELECT
  ISBN,
  Book_Title,
  Book_Author,
  CAST(Year_Of_Publication AS INT) AS Year_Of_Publication,
  Publisher,
  Image_URL_S,
  Image_URL_M,
  Image_URL_L
FROM books;

CREATE VIEW ratings_view AS
SELECT
  CAST(User_ID AS INT) AS User_ID,
  ISBN,
  CAST(Book_Rating AS INT) AS Book_Rating
FROM ratings;

CREATE VIEW users_view AS
SELECT
  CAST(User_ID AS INT) AS User_ID,
  Location,
  CAST(Age AS INT) AS Age
FROM users;
```

# ë°ì´í„° í™•ì¸

## ì¤‘ë³µ ë°ì´í„° í™•ì¸

**Books í…Œì´ë¸”ì—ì„œ ì¤‘ë³µëœ ISBN í™•ì¸**

```sql
SELECT isbn, COUNT(*) FROM books_view
GROUP BY isbn
HAVING COUNT(*) > 1;
```

- ISBNë³„ ê¸°ë¡ ìˆ˜ ê³„ì‚°
- ISBNì´ 2ê°œ ì´ìƒ ë‹¤ì¤‘ ë‚˜ì˜¤ëŠ” ê²½ìš°ë§Œ í‘œì‹œ

> **COUNT(*)** : NULLì—†ì´ ê¸°ë¡ì„ 1íšŒì”© ê³„ì‚°
> **COUNT(í…Œì´ë¸”.ì»¬ëŸ¼ëª…)** : NULLì´ ì•„ë‹ˆë©´ 1íšŒì”© ê³„ì‚°

## ê²°ì‰¬ê°„ í™•ì¸

**Users í…Œì´ë¸”ì—ì„œ Ageì˜ ê²°ì‰¬ê°„ í™•ì¸**

```sql
SELECT COUNT(*)
FROM users_view
WHERE age IS NULL;
```

# ë°ì´í„°ì˜ ê¸°ì´ˆ í†µê³„ í™•ì¸

## ì‚¬ìš©ì ì—°ë ¹ í†µê³„

```sql
SELECT MAX(age), MIN(age), AVG(age) FROM users_view;
```

## ì¶œíŒ ì—°ë„ í†µê³„

```sql
SELECT MAX(year_of_publication), MIN(year_of_publication), AVG(year_of_publication) FROM books_view;
```

### ì»¬ëŸ¼ í™•ì¸ ìë¦¬

| ìƒí™© | ê°€ì¥ ê¶Œìš© ìˆëŠ” ë©”ì„œë“œ |
|:---|:---|
| ì»¬ëŸ¼ ì´ë¦„ + íƒ€ì…ë§Œ ë³´ê³  ì‹¶ì„ ë•Œ | DESCRIBE í…Œì´ë¸” |
| ì»¬ëŸ¼ ì´ë¦„ë§Œ ë³´ê³  ì‹¶ì„ ë•Œ | SHOW COLUMNS IN í…Œì´ë¸” |
| ì‹œê°„ ì˜ˆëŠ¥ + ì»¬ëŸ¼ ì´ë¦„ + ë°ì´í„° í˜•ì‹ ê°™ì´ | SELECT * FROM í…Œì´ë¸” LIMIT 1 |

## í‰ì ì˜ ë¶„í¬ í™•ì¸

```sql
SELECT book_rating, COUNT(*) FROM ratings_view
GROUP BY book_rating;
```

# ë°ì´í„°ì˜ ì£¼ìš” íŒ¨í„´ íƒìƒ‰

## ì¶œíŒì‚¬ë³„ ì±… ìˆ˜ ë° í‰ê·  í‰ì 

```sql
SELECT
  books_view.publisher,
  COUNT(books_view.isbn),
  AVG(ratings_view.book_rating)
FROM
  books_view
JOIN
  ratings_view
ON
  books_view.isbn = ratings_view.isbn
GROUP BY
  books_view.publisher
ORDER BY
  COUNT(books_view.isbn) DESC;
```

- **í•„ìš” í–‰ì • ìˆœì„œ**
    - books_view (cd ì§€ì •)
    - JOIN ratings_view
    - GROUP BY publisher
    - ORDER BY count

## ê°€ì¥ ë§ì´ í‰ê°€ëœ ì±…ê³¼ í‰ì 

```sql
SELECT books_view.book_title, COUNT(books_view.isbn), AVG(ratings_view.book_rating)
FROM books_view
JOIN ratings_view
ON books_view.isbn = ratings_view.isbn
GROUP BY books_view.book_title
ORDER BY COUNT(books_view.isbn) DESC;
```

# ë°ì´í„° ê´€ê³„ ë¶„ì„

## ì±… í‰ì ê³¼ ì¶œíŒì—°ë„ê°€ ê°™ì´ ê´€ê³„

```sql
SELECT b.year_of_publication, AVG(r.book_rating)
FROM books_view b
JOIN ratings_view r
ON b.isbn = r.isbn
GROUP BY b.year_of_publication;
```

## ì‚¬ìš©ì ìœ„ì¹˜ë³„ í‰ì  ì°¨ì´

(í‰ì  ì´ 10ê°œ ì´ìƒì¸ ê²½ìš°ë§Œ)

```sql
SELECT u.location, AVG(r.book_rating)
FROM users_view u
JOIN ratings_view r
ON u.user_id = r.user_id
GROUP BY u.location
HAVING COUNT(r.book_rating) >= 10;
```

### ì‹œê°„ ì‹œê°„ í™•ì¸í•˜ì

| êµ¬ë¬¸ | í•¨ì • | ë¬´ì—‡ì´ ì™€ì•¼í• ê²ƒì¸ê°€? |
|:---|:---|:---|
| ON | ë‘ í…Œì´ë¸”ì˜ ê³µí†µì  ê°™ì´ ì—°ê²° | ex: a.id = b.user_id |
| WHERE | ê±°ë˜ ê°’ì— ëŒ€í•œ í¬ì¸íŠ¸ ê²€ìƒ‰ | ex: age > 20 |
| GROUP BY | ê·¸ë£¹í•  ì»¬ëŸ¼ ì§€ì • | ex: country |
| HAVING | ê·¸ë£¹ í›„ ê³„ì‚°ì  ê²°ê³¼ì— ê²€ìƒ‰ | ex: COUNT(*) > 10 |

## ì±… ì €ìë³„ í‰ê·  í‰ì 

```sql
SELECT b.book_author, AVG(r.book_rating), COUNT(r.isbn)
FROM books_view b
JOIN ratings_view r
ON b.isbn = r.isbn
GROUP BY b.book_author
HAVING COUNT(r.book_rating) >= 10
ORDER BY AVG(r.book_rating) DESC;
```

- FROM â†’ JOIN â†’ ON â†’ WHERE â†’ GROUP BY â†’ HAVING â†’ SELECT â†’ ORDER BY ìˆœ

# \<AIRLINE\>

## ìš”ì¼ë³„ ì¶œë°œ / ë„ì°© ì§€ì—­ ê´„ì°° í‰ê· 

```sql
SELECT DayOfWeek, AVG(DepDelay), AVG(ArrDelay)
FROM airline
GROUP BY DayOfWeek;
```

## í•­ê³µì‚¬ë³„, ì›”ë³„ ì§€ì—­ ë° ìš´í–‰ ê±´ìˆ˜

```sql
SELECT UniqueCarrier, Month, COUNT(*), AVG(depDelay)
FROM airline
GROUP BY UniqueCarrier, Month;
```

## ì „ì²´ ë°ì´í„°ì—ì„œ ì¶œë°œ ì§€ì—­ í‰ê· 

```sql
SELECT
  (SUM(CASE WHEN DepDelay > 0 THEN 1 ELSE 0 END) * 100.0) / COUNT(*) AS delayed_percentage
FROM airline;
```

## í•­ê³µì‚¬ë³„ ì·¨ì†Œ\ucìœ¨

```sql
SELECT UniqueCarrier, (SUM(Cancelled) / COUNT(*) * 100) AS cancel_rate
FROM airline
GROUP BY UniqueCarrier;
```

## ê°€ì¥ ë¶ˆë¹„ë˜ëŠ” ê³µí•­

```sql
SELECT
    airport,
    SUM(cnt) AS total
FROM
(
    SELECT Origin AS airport, COUNT(*) AS cnt
    FROM airline
    GROUP BY Origin

    UNION ALL

    SELECT Dest AS airport, COUNT(*) AS cnt
    FROM airline
    GROUP BY Dest
) AS combined
GROUP BY airport
ORDER BY total DESC
LIMIT 10;
```

## ì‹¤ì œ ë¹„í–‰ì‹œê°„ / ì˜ˆìƒ ë¹„í–‰ì‹œê°„ ì°¨ì´ê°€ í° ë¹„í–‰ ë…¸ì„ 

```sql
SELECT *, ABS(real_time - crs_time) AS time_diff
FROM (
    SELECT Origin, Dest,
           AVG(ActualElapsedTime) AS real_time,
           AVG(CRSElapsedTime) AS crs_time
    FROM airline
    GROUP BY Origin, Dest
) t
ORDER BY time_diff DESC;
```

> **í•˜ì§€ë§Œ ì •ì  SQLì—ì„œëŠ” ìˆ˜í–‰ ì¤‘ì— ê°™ì€ ê³„ì‚°ìê°€ ì—­ë²•ìƒ ë°œìƒì—†ê¸° í•˜ê¸° ìœ„í•´** ì„œë¸Œì¿¨ë¦¬ (SELECTêµ¬ë¬¸) ë¥¼ í•´ì„

---

# PYSPARK 

## ìš”ì¼ë³„ ì¶œë°œ / ë„ì°© ì§€ì—­ í‰ê·  (PySpark)

```python
airline.groupBy('DayOfWeek').agg(
    avg('DepDelay').alias('avg_dep_delay'),
    avg('ArrDelay').alias('avg_arr_delay')
).show()
```

## í•­ê³µì‚¬ë³„ ì›”ë³„ ì§€ì—­ ë° ìš´í–‰ ê±´ìˆ˜ (PySpark)

```python
airline.groupBy('UniqueCarrier', 'Month').agg(
    count('*').alias('flight_count'),
    avg('DepDelay').alias('avg_dep_delay')
).show()
```

## ì¶œë°œì§€(PySpark)

```python
airline.groupBy('Origin').count().orderBy('count', ascending=False).show()
```

## ë„ì°©ì§€ (PySpark)

```python
airline.groupBy('Dest').count().orderBy('count', ascending=False).show()
```

## ê°€ì¥ ë¶ë¹„ëŠ” ê³µí•­ (PySpark)

```python
origin = airline.groupBy('Origin').count()
dest = airline.groupBy('Dest').count()

combined = origin.unionByName(dest)

combined.groupBy('Origin').agg(
    sum('count').alias('total')
).orderBy('total', ascending=False).show()
```

## ì‹¤ì œì‹œê°„ / ì˜ˆìƒì‹œê°„ ì°¨ì´ê°€ í° ë¹„í–‰êµ¬ê°„ (PySpark)

```python
from pyspark.sql.functions import abs, avg

airline.groupBy('Origin', 'Dest').agg(
    avg('ActualElapsedTime').alias('real_time'),
    avg('CRSElapsedTime').alias('crs_time')
).withColumn(
    'diff_time', abs(col('real_time') - col('crs_time'))
).orderBy('diff_time', ascending=False).show()
```

