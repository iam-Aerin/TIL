### 견고한 데이터 엔지니어링
## Fundamentals of Data Engineering

데이터 엔지니어링은 데이터를 생성하고, 수집하고, 분석 가능한 형태로 전달하는 **데이터 파이프라인을 설계하고 운영하는 과정**이다.

---

## 1. 데이터 엔지니어링의 전체 흐름


> 이 모든 과정은 보안, 데이터 관리, 소프트웨어 엔지니어링, 아키텍처 설계 등 보이지 않는 요소들과 함께 작동한다.

--- 

## 2. 정형 데이터 vs 비정형 데이터

| 구분         | 설명                                                 | 예시                   |
|--------------|------------------------------------------------------|------------------------|
| 정형 데이터  | 구조화된 테이블 형태로 저장되는 데이터              | RDBMS (MySQL, Postgres 등) |
| 비정형 데이터| 구조가 일정하지 않은 데이터, 파일 단위로 저장됨     | 로그 파일(.log, .txt), JSON, 이미지 등 |

- **RDBMS**: 관계형 데이터베이스 시스템  
  - `INSERT`를 통해 데이터가 일련번호(id)와 함께 저장됨  
  - 테이블 형태로 구조화되어 있음

- **로그(log)**: 비정형 데이터  
  - 단순히 시간 순으로 쌓이는 데이터  
  - ID가 없이 append 형태로 추가됨  
  - 주로 `.log`, `.txt` 파일 등으로 저장됨

---

## 3. Hadoop의 역할

Hadoop은 위의 **비정형 데이터**를 저장하고 처리하는 데 특화된 프레임워크다.

- 다양한 형태의 원시 데이터를 수집하고 저장
- 그 중 필요한 요소만 추출하고 정제
- 대용량 데이터를 효율적으로 분산 저장(HDFS) 및 처리(MapReduce)

---

## 4. 데이터 정제란?

> 원시 데이터(raw data)에서 필요한 정보만 꺼내는 과정

예시:
- 어떤 **URL**로 요청이 왔는가?
- 어떤 **IP 주소**에서 접속했는가?

이처럼 로그 파일에서 특정 컬럼(필드)만 선택해서 유용한 데이터셋으로 정리하는 작업

---
> 데이터엔지니어링 수명 주기
![alt text](image.png)

## 5. ETL: Extract - Transform - Load

데이터 파이프라인의 대표적인 처리 흐름

| 단계     | 설명                                           |
|----------|------------------------------------------------|
| Extract  | 데이터를 원천(source)에서 추출                 |
| Transform| 분석 또는 저장에 적합하도록 변환               |
| Load     | 목적지(destination)에 저장 또는 전송           |

ETL은 데이터 분석, 머신러닝, 데이터 시각화를 위한 전처리의 핵심 단계다.

---

## 6. 그 외 고려해야 할 요소들

데이터 엔지니어링은 기술적으로만 구성되지 않는다. 다양한 인프라와 운영 요소들이 함께 설계되어야 한다.

- **보안**: 데이터 접근 권한, 암호화, 개인정보 보호
- **데이터 관리**: 스키마, 품질 관리, 메타데이터 관리
- **데이터 아키텍처**: 어떤 기술로 어떤 구조를 구성할 것인가
- **오케스트레이션**: 여러 작업을 정해진 순서대로 자동화
- **소프트웨어 엔지니어링**: 테스트, 배포, 형상관리 등
- **데이터옵스**: 데이터 엔지니어링의 운영 및 자동화 문화

---

## 정리

- 데이터 엔지니어링은 데이터를 흐르게 만드는 기술
- Hadoop은 비정형 데이터를 저장하고 처리하는 도구
- ETL은 데이터를 유용하게 만드는 핵심 처리 흐름
- 파이프라인 뒤에는 보이지 않는 인프라와 운영 요소들이 존재


>![The Data Hierarchy of Needs](https://blog.kakaocdn.net/dn/cUzWS1/btsyEybj3jN/9uw6RSNcbSQ3ZDosTu6tA1/img.png)

---
# TIL: Hadoop 기초 개념 정리

## 오늘의 학습 목표
- 데이터 엔지니어링에서 Hadoop이 어떤 역할을 하는지 이해하기
- Hadoop의 기본 구성요소(HDFS, MapReduce 등)를 개념적으로 정리하기

---

`Hadoop`, `하이브`, `HBase`, `스파크` 기술에서 선택하여 
: 보통 하이브는 SQL로, 스파크는 파이썬으로 사용한다.
---

## Hadoop이란?

Hadoop은 대용량 데이터를 분산 저장하고 처리하기 위한 오픈소스 프레임워크이다.

- 대용량(Big Data) 데이터를 처리하기 위해 설계됨
- 여러 대의 컴퓨터(클러스터)를 연결해 분산 처리
- 장애 발생 시에도 자동으로 복구할 수 있는 내결함성(Fault-tolerance)을 보장

---
![Hadoop ecosystem](https://www.edureka.co/blog/wp-content/uploads/2016/10/HADOOP-ECOSYSTEM-Edureka.png)

## Hadoop의 핵심 구성요소

### 1. HDFS (Hadoop Distributed File System)

Hadoop의 분산 파일 시스템으로, 데이터를 여러 노드에 나눠서 저장한다.

- 데이터를 여러 서버에 나눠 저장함으로써 병렬 접근 가능
- 기본적으로 데이터는 3개의 복제본으로 저장되어 안전성을 확보

구성 요소:
- NameNode: 메타데이터 관리 (파일 이름, 위치, 권한 등)
- DataNode: 실제 데이터 블록을 저장

### 2. MapReduce

Hadoop에서 데이터를 처리하는 핵심 프로그래밍 모델

- 데이터를 나눠서 처리(Map)하고, 그 결과를 모아서 정리(Reduce)
- 대규모 데이터를 병렬로 처리할 수 있는 구조

예시: 단어 빈도수 세기  
- Map 단계: 각 문장에서 단어를 (word, 1) 형태로 분리  
- Reduce 단계: 같은 단어끼리 묶어서 합산하여 (word, count) 형태로 결과 도출

---

## Hadoop의 장점

- 확장성: 서버를 쉽게 추가하여 시스템 확장 가능
- 비용 효율성: 저렴한 하드웨어로도 운영 가능
- 내결함성: 일부 노드가 고장나도 데이터 손실 없이 복구 가능
- 오픈소스: 자유롭게 사용 및 수정 가능

---

## 전통 시스템과의 비교

| 항목         | 전통 시스템     | Hadoop                |
|--------------|------------------|------------------------|
| 저장 방식    | 중앙 집중형     | 분산 저장 (HDFS)       |
| 처리 방식    | 단일 프로세서   | 병렬 분산 처리 (MapReduce) |
| 확장성       | 제한적           | 수평적 확장 가능         |
| 장애 대응    | 취약             | 내결함성 제공            |

---

## 키워드

- Hadoop
- HDFS
- MapReduce
- 분산 처리
- 내결함성

---

### Hadoop 책  (p.41)

```
예전에 사람들은 무거운 것을 끌기 위해 소를 이용했다. 그리고 소 한 마리가 통나무 하나를 움직일 수 없을 때 그 소를 더 키우려 애쓰지 않았다. 우리에게 필요한 것은 커다란 한 대의 컴퓨터이다. 
```
> Hadoop은 커다란 한 대의 컴퓨터를 사용하여 데이터를 분산 처리하는 데 사용된다.

![alt text](image-1.png)

![how do hard disk drives work](https://animagraffs.com/wp-content/uploads/how-hard-disk-drives-work-1.png)

---
### 분산 컴퓨팅: 여러 개의 디스크에 데이터를 병렬로 쓰거나 읽게 하자
하지만 이는 문제가 발생 할 수 있음
> 하드웨어 장애
> 분할된 데이터를 대부분의 분석 작업에서 어떤 식으로든 결합해야 한다. 
>
>  `하둡 (Hadoop)`은 이를 해결하기 위해 사용하는 대표적인 분산 컴퓨팅 기술이다: 범용 하드웨어에서 실행되고 오픈 소스이기 때문에 매우 저렴하다. 

`하둡 (Hadoop)`과 `RDBMS`는 어떻게 다른가? 
```
맵리듀스라는 방식으로 느린 RDBMS를 보완한다. 

- RDBMS:의 목적은 CRUD를 하는 것! - 여러 번 읽고 쓰기
- 맵리듀스: CR만을 처리한다. (수정을 고려하지 않음) - 계속 쌓아서 보기 위한 = 한 번 쓰고 여러 번 읽는 것을 목적으로 
```

### 하둡의 분산파일 시스템
: HDFS (Hadoop Distributed File System)
> 하둡은 여러 개의 디스크에 데이터를 병렬로 쓰거나 읽게 하자
```
매우 큰 파일
스트리밍 방식의 데이터 접근
범용 하드웨어
오픈 소스
```
하둡의 HDFS는 다음과 같은 특징을 가진다. 
```
- 빠른 읽기와 쓰기
- 빠른 분산 처리
- 빠른 분산 저장
- 빠른 분산 접근
- 빠른 분산 관리
- 빠른 분산 보안
```
단점
```
빠른 데이터 응답 시간
수많은 작은 파일
다중 라이터와 파일의 임의 수정
```

### HDFS 개념
`블록`: 128MB

---